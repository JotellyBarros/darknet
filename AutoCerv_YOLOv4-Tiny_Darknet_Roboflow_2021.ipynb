{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## STEP 1. Install"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuring cuDNN on Colab for YOLOv4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
                "!/usr/local/cuda/bin/nvcc - -version\n",
                "# sudo apt install nvidia-cuda-toolkit\n",
                "# We need to install the correct cuDNN according to this output\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This cell ensures you have the correct architecture for your respective GPU\n",
                "# If you command is not found, look through these GPUs, find the respective\n",
                "# GPU and add them to the archTypes dictionary\n",
                "\n",
                "# Tesla V100\n",
                "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
                "\n",
                "# Tesla K80\n",
                "# ARCH= -gencode arch=compute_37,code=sm_37\n",
                "\n",
                "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
                "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
                "\n",
                "# Jetson XAVIER\n",
                "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
                "\n",
                "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
                "# ARCH= -gencode arch=compute_61,code=sm_61\n",
                "\n",
                "# GP100/Tesla P100 - DGX-1\n",
                "# ARCH= -gencode arch=compute_60,code=sm_60\n",
                "\n",
                "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
                "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
                "\n",
                "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
                "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
                "import os\n",
                "os.environ['GPU_TYPE'] = str(\n",
                "    os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
                "\n",
                "\n",
                "def getGPUArch(argument):\n",
                "    try:\n",
                "        argument = argument.strip()\n",
                "        # All Colab GPUs\n",
                "        archTypes = {\n",
                "            \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
                "            \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
                "            \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
                "            \"GeForce GTX 1060 6GB\": \"-gencode arch=compute_61,code=sm_61\",\n",
                "            \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
                "\n",
                "        }\n",
                "        return archTypes[argument]\n",
                "    except KeyError:\n",
                "        return \"GPU must be added to GPU Commands\"\n",
                "\n",
                "\n",
                "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
                "\n",
                "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
                "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Installing Darknet for YOLOv4 on Colab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# %sudo chmod -R 777 /content\n",
                "%cd / content/\n",
                "%rm - rf darknet\n",
                "%mkdir - p / content/darknet/\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd / content/\n",
                "# !git clone https://github.com/roboflow-ai/darknet.git\n",
                "!git clone https: // github.com/AlexeyAB/darknet.git\n",
                "\n",
                "# download object-detection-yolo-opencv\n",
                "!git clone https: // github.com/JotellyBarros/object-detection-yolo-opencv.git\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install environment from the Makefile\n",
                "# note if you are on Colab Pro this works on a P100 GPU\n",
                "# if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
                "# this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
                "# note the Makefile above should work for you, if you need to tweak, try the below\n",
                "%cd / content/darknet/\n",
                "# !sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
                "# !sed -i 's/GPU=0/GPU=1/g' Makefile\n",
                "# !sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
                "# !sed -i \"s/ARCH= -gencode arch=compute_61,code=sm_61/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
                "!make clean\n",
                "!make\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# download the newly released yolov4-tiny ConvNet weights\n",
                "%cd / content/darknet\n",
                "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
                "!wget https: // github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set up Custom Dataset for YOLOv4\n",
                "\n",
                "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format. \n",
                "\n",
                "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
                "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
                "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
                "4. Export your dataset in the **YOLO Darknet format**.\n",
                "5. Copy your download link, and paste it below.\n",
                "\n",
                "See our [blog post](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) for greater detail.\n",
                "\n",
                "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if you already have YOLO darknet format, you can skip this step\n",
                "%cd / content/darknet\n",
                "!curl - L \"https://app.roboflow.com/ds/P8F8YLMLYe?key=0KN7FVT4h7\" > roboflow.zip\n",
                "unzip roboflow.zip\n",
                "rm roboflow.zip\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Errno 2] No such file or directory: '/ content/darknet/'\n",
                        "/content/darknet\n"
                    ]
                }
            ],
            "source": [
                "# Set up training file directories for custom dataset\n",
                "import os\n",
                "%cd / content/darknet/\n",
                "%cp train/_darknet.labels data/obj.names\n",
                "# %mkdir data/obj\n",
                "# copy image and labels\n",
                "%cp train/*.jpg data/obj/\n",
                "%cp valid/*.jpg data/obj/\n",
                "\n",
                "%cp train/*.txt data/obj/\n",
                "%cp valid/*.txt data/obj/\n",
                "\n",
                "with open('data/obj.data', 'w') as out:\n",
                "    out.write('classes = 1\\n')\n",
                "    out.write('train = data/train.txt\\n')\n",
                "    out.write('valid = data/valid.txt\\n')\n",
                "    out.write('names = data/obj.names\\n')\n",
                "    out.write('backup = backup/')\n",
                "\n",
                "# write train file (just the image list)\n",
                "\n",
                "with open('data/train.txt', 'w') as out:\n",
                "    for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
                "        out.write('data/obj/' + img + '\\n')\n",
                "\n",
                "# write the valid file (just the image list)\n",
                "\n",
                "with open('data/valid.txt', 'w') as out:\n",
                "    for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
                "        out.write('data/obj/' + img + '\\n')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Write Custom Training Config for YOLOv4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Errno 2] No such file or directory: '/ content/darknet/cfg/'\n",
                        "/content/darknet\n",
                        "--2022-04-06 12:59:31--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n",
                        "Resolvendo github.com (github.com)... 20.201.28.151\n",
                        "Conectando-se a github.com (github.com)|20.201.28.151|:443... conectado.\n",
                        "A requisição HTTP foi enviada, aguardando resposta... 302 Found\n",
                        "Localização: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/28807d00-3ea4-11eb-97b5-4c846ecd1d05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220406%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220406T155931Z&X-Amz-Expires=300&X-Amz-Signature=c97bac125598fe6a7938b247d797ddc4417662eef9d467303ac4e00e7c81fe75&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.conv.29&response-content-type=application%2Foctet-stream [redirecionando]\n",
                        "--2022-04-06 12:59:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/28807d00-3ea4-11eb-97b5-4c846ecd1d05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220406%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220406T155931Z&X-Amz-Expires=300&X-Amz-Signature=c97bac125598fe6a7938b247d797ddc4417662eef9d467303ac4e00e7c81fe75&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.conv.29&response-content-type=application%2Foctet-stream\n",
                        "Resolvendo objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
                        "Conectando-se a objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... conectado.\n",
                        "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
                        "Tamanho: 19789716 (19M) [application/octet-stream]\n",
                        "Salvando em: “yolov4-tiny.conv.29”\n",
                        "\n",
                        "yolov4-tiny.conv.29 100%[===================>]  18.87M  19.1MB/s    em 1.0s    \n",
                        "\n",
                        "2022-04-06 12:59:33 (19.1 MB/s) - “yolov4-tiny.conv.29” salvo [19789716/19789716]\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "%cd / content/darknet/cfg/\n",
                "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
                "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/content/darknet\n",
                        "writing config for a custom YOLOv4 detector detecting number of classes: 1\n"
                    ]
                }
            ],
            "source": [
                "%cd /content/darknet/\n",
                "# we build config dynamically based on number of classes\n",
                "# we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
                "\n",
                "\n",
                "def file_len(fname):\n",
                "    with open(fname) as f:\n",
                "        for i, l in enumerate(f):\n",
                "            pass\n",
                "    return i + 1\n",
                "\n",
                "num_classes = file_len('train/_darknet.labels')\n",
                "max_batches = num_classes*2000\n",
                "steps1 = .8 * max_batches\n",
                "steps2 = .9 * max_batches\n",
                "steps_str = str(steps1)+','+str(steps2)\n",
                "num_filters = (num_classes + 5) * 3\n",
                "\n",
                "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
                "\n",
                "# Instructions from the darknet repo\n",
                "# change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
                "# change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
                "# if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
                "\n",
                "@register_line_cell_magic\n",
                "def writetemplate(line, cell):\n",
                "    with open(line, 'w') as f:\n",
                "        f.write(cell.format(**globals()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
                "[net]\n",
                "# Testing\n",
                "#batch=1\n",
                "#subdivisions=1\n",
                "# Training\n",
                "batch=64\n",
                "subdivisions=16\n",
                "width=416\n",
                "height=416\n",
                "channels=3\n",
                "momentum=0.9\n",
                "decay=0.0005\n",
                "angle=0\n",
                "saturation = 1.5\n",
                "exposure = 1.5\n",
                "hue=.1\n",
                "\n",
                "learning_rate=0.00261\n",
                "burn_in=1000\n",
                "max_batches = {max_batches}\n",
                "policy=steps\n",
                "steps={steps_str}\n",
                "scales=.1,.1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=2\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=2\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=512\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "##################################\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=512\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "filters={num_filters}\n",
                "activation=linear\n",
                "\n",
                "[yolo]\n",
                "mask = 3,4,5\n",
                "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                "classes={num_classes}\n",
                "num=6\n",
                "jitter=.3\n",
                "scale_x_y = 1.05\n",
                "cls_normalizer=1.0\n",
                "iou_normalizer=0.07\n",
                "iou_loss=ciou\n",
                "ignore_thresh = .7\n",
                "truth_thresh = 1\n",
                "random=0\n",
                "nms_kind=greedynms\n",
                "beta_nms=0.6\n",
                "\n",
                "[route]\n",
                "layers = -4\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[upsample]\n",
                "stride=2\n",
                "\n",
                "[route]\n",
                "layers = -1, 23\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "filters={num_filters}\n",
                "activation=linear\n",
                "\n",
                "[yolo]\n",
                "mask = 1,2,3\n",
                "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                "classes={num_classes}\n",
                "num=6\n",
                "jitter=.3\n",
                "scale_x_y = 1.05\n",
                "cls_normalizer=1.0\n",
                "iou_normalizer=0.07\n",
                "iou_loss=ciou\n",
                "ignore_thresh = .7\n",
                "truth_thresh = 1\n",
                "random=0\n",
                "nms_kind=greedynms\n",
                "beta_nms=0.6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[net]\n",
                        "# Testing\n",
                        "#batch=1\n",
                        "#subdivisions=1\n",
                        "# Training\n",
                        "batch=64\n",
                        "subdivisions=16\n",
                        "width=416\n",
                        "height=416\n",
                        "channels=3\n",
                        "momentum=0.9\n",
                        "decay=0.0005\n",
                        "angle=0\n",
                        "saturation = 1.5\n",
                        "exposure = 1.5\n",
                        "hue=.1\n",
                        "\n",
                        "learning_rate=0.00261\n",
                        "burn_in=1000\n",
                        "max_batches = 2000\n",
                        "policy=steps\n",
                        "steps=1600.0,1800.0\n",
                        "scales=.1,.1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=2\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=2\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=512\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "##################################\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=512\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "filters=18\n",
                        "activation=linear\n",
                        "\n",
                        "[yolo]\n",
                        "mask = 3,4,5\n",
                        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                        "classes=1\n",
                        "num=6\n",
                        "jitter=.3\n",
                        "scale_x_y = 1.05\n",
                        "cls_normalizer=1.0\n",
                        "iou_normalizer=0.07\n",
                        "iou_loss=ciou\n",
                        "ignore_thresh = .7\n",
                        "truth_thresh = 1\n",
                        "random=0\n",
                        "nms_kind=greedynms\n",
                        "beta_nms=0.6\n",
                        "\n",
                        "[route]\n",
                        "layers = -4\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[upsample]\n",
                        "stride=2\n",
                        "\n",
                        "[route]\n",
                        "layers = -1, 23\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "filters=18\n",
                        "activation=linear\n",
                        "\n",
                        "[yolo]\n",
                        "mask = 1,2,3\n",
                        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                        "classes=1\n",
                        "num=6\n",
                        "jitter=.3\n",
                        "scale_x_y = 1.05\n",
                        "cls_normalizer=1.0\n",
                        "iou_normalizer=0.07\n",
                        "iou_loss=ciou\n",
                        "ignore_thresh = .7\n",
                        "truth_thresh = 1\n",
                        "random=0\n",
                        "nms_kind=greedynms\n",
                        "beta_nms=0.6\n"
                    ]
                }
            ],
            "source": [
                "# here is the file that was just written.\n",
                "# you may consider adjusting certain things\n",
                "\n",
                "# like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
                "# if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
                "%cat cfg/custom-yolov4-tiny-detector.cfg\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Custom YOLOv4 Detector"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " CUDA-version: 11040 (11040), cuDNN: 8.2.2, GPU count: 1  \n",
                        " OpenCV version: 4.2.0\n",
                        "custom-yolov4-tiny-detector\n",
                        " 0 : compute_capability = 750, cudnn_half = 0, GPU: NVIDIA GeForce RTX 2070 with Max-Q Design \n",
                        "net.optimized_memory = 0 \n",
                        "mini_batch = 2, batch = 48, time_steps = 1, train = 1 \n",
                        "   layer   filters  size/strd(dil)      input                output\n",
                        "   0 Create CUDA-stream - 0 \n",
                        " Create cudnn-handle 0 \n",
                        "conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n",
                        "   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n",
                        "   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n",
                        "   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n",
                        "   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n",
                        "   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n",
                        "   6 route  5 4 \t                           ->  104 x 104 x  64 \n",
                        "   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n",
                        "   8 route  2 7 \t                           ->  104 x 104 x 128 \n",
                        "   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n",
                        "  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n",
                        "  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n",
                        "  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n",
                        "  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n",
                        "  14 route  13 12 \t                           ->   52 x  52 x 128 \n",
                        "  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n",
                        "  16 route  10 15 \t                           ->   52 x  52 x 256 \n",
                        "  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n",
                        "  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n",
                        "  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n",
                        "  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n",
                        "  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n",
                        "  22 route  21 20 \t                           ->   26 x  26 x 256 \n",
                        "  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n",
                        "  24 route  18 23 \t                           ->   26 x  26 x 512 \n",
                        "  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n",
                        "  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n",
                        "  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n",
                        "  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n",
                        "  29 Darknet error location: ./src/dark_cuda.c, cuda_make_array, line #499\n",
                        "Cuda malloc failed: Success\n"
                    ]
                }
            ],
            "source": [
                "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 - dont_show - map\n",
                "# If you get CUDA out of memory adjust subdivisions above!\n",
                "# adjust max batches down for shorter training above\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
