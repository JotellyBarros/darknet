{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## STEP 1. Install"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuring cuDNN on Colab for YOLOv4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
                "!/usr/local/cuda/bin/nvcc - -version\n",
                "# sudo apt install nvidia-cuda-toolkit\n",
                "# We need to install the correct cuDNN according to this output\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This cell ensures you have the correct architecture for your respective GPU\n",
                "# If you command is not found, look through these GPUs, find the respective\n",
                "# GPU and add them to the archTypes dictionary\n",
                "\n",
                "# Tesla V100\n",
                "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
                "\n",
                "# Tesla K80\n",
                "# ARCH= -gencode arch=compute_37,code=sm_37\n",
                "\n",
                "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
                "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
                "\n",
                "# Jetson XAVIER\n",
                "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
                "\n",
                "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
                "# ARCH= -gencode arch=compute_61,code=sm_61\n",
                "\n",
                "# GP100/Tesla P100 - DGX-1\n",
                "# ARCH= -gencode arch=compute_60,code=sm_60\n",
                "\n",
                "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
                "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
                "\n",
                "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
                "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
                "import os\n",
                "os.environ['GPU_TYPE'] = str(\n",
                "    os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
                "\n",
                "\n",
                "def getGPUArch(argument):\n",
                "    try:\n",
                "        argument = argument.strip()\n",
                "        # All Colab GPUs\n",
                "        archTypes = {\n",
                "            \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
                "            \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
                "            \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
                "            \"GeForce GTX 1060 6GB\": \"-gencode arch=compute_61,code=sm_61\",\n",
                "            \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
                "\n",
                "        }\n",
                "        return archTypes[argument]\n",
                "    except KeyError:\n",
                "        return \"GPU must be added to GPU Commands\"\n",
                "\n",
                "\n",
                "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
                "\n",
                "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
                "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Installing Darknet for YOLOv4 on Colab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# %sudo chmod -R 777 /content\n",
                "%cd / content/\n",
                "%rm - rf darknet\n",
                "%mkdir - p / content/darknet/\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd / content/\n",
                "# !git clone https://github.com/roboflow-ai/darknet.git\n",
                "!git clone https: // github.com/AlexeyAB/darknet.git\n",
                "\n",
                "# download object-detection-yolo-opencv\n",
                "!git clone https: // github.com/JotellyBarros/object-detection-yolo-opencv.git\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install environment from the Makefile\n",
                "# note if you are on Colab Pro this works on a P100 GPU\n",
                "# if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
                "# this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
                "# note the Makefile above should work for you, if you need to tweak, try the below\n",
                "%cd / content/darknet/\n",
                "# !sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
                "# !sed -i 's/GPU=0/GPU=1/g' Makefile\n",
                "# !sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
                "# !sed -i \"s/ARCH= -gencode arch=compute_61,code=sm_61/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
                "!make clean\n",
                "!make\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# download the newly released yolov4-tiny ConvNet weights\n",
                "%cd / content/darknet\n",
                "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
                "!wget https: // github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set up Custom Dataset for YOLOv4\n",
                "\n",
                "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format. \n",
                "\n",
                "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
                "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
                "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
                "4. Export your dataset in the **YOLO Darknet format**.\n",
                "5. Copy your download link, and paste it below.\n",
                "\n",
                "See our [blog post](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) for greater detail.\n",
                "\n",
                "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# if you already have YOLO darknet format, you can skip this step\n",
                "%cd /content/darknet\n",
                "!curl -L \"https://app.roboflow.com/ds/0a6no5RTO2?key=CySLKuHmB7\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/content/darknet\n",
                        "writing config for a custom YOLOv4 detector detecting number of classes: 5\n"
                    ]
                }
            ],
            "source": [
                "# Set up training file directories for custom dataset\n",
                "import os\n",
                "%cd /content/darknet/\n",
                "%cp train/_darknet.labels data/obj.names\n",
                "# %mkdir data/obj\n",
                "# copy image and labels\n",
                "%cp train/*.jpg data/obj/\n",
                "%cp valid/*.jpg data/obj/\n",
                "\n",
                "%cp train/*.txt data/obj/\n",
                "%cp valid/*.txt data/obj/\n",
                "\n",
                "def file_len(fname):\n",
                "  with open(fname) as f:\n",
                "    for i, l in enumerate(f):\n",
                "      pass\n",
                "  return i + 1\n",
                "\n",
                "num_classes = file_len('train/_darknet.labels')\n",
                "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
                "\n",
                "with open('data/obj.data', 'w') as out:\n",
                "    out.write('classes = '+ str(num_classes)+'\\n')\n",
                "    out.write('train = data/train.txt\\n')\n",
                "    out.write('valid = data/valid.txt\\n')\n",
                "    out.write('names = data/obj.names\\n')\n",
                "    out.write('backup = backup/')\n",
                "\n",
                "# write train file (just the image list)\n",
                "\n",
                "with open('data/train.txt', 'w') as out:\n",
                "    for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
                "        out.write('data/obj/' + img + '\\n')\n",
                "\n",
                "# write the valid file (just the image list)\n",
                "\n",
                "with open('data/valid.txt', 'w') as out:\n",
                "    for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
                "        out.write('data/obj/' + img + '\\n')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Write Custom Training Config for YOLOv4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd / content/darknet/cfg/\n",
                "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
                "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/content/darknet\n",
                        "writing config for a custom YOLOv4 detector detecting number of classes: 5\n"
                    ]
                }
            ],
            "source": [
                "%cd /content/darknet/\n",
                "# we build config dynamically based on number of classes\n",
                "# we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
                "\n",
                "\n",
                "def file_len(fname):\n",
                "    with open(fname) as f:\n",
                "        for i, l in enumerate(f):\n",
                "            pass\n",
                "    return i + 1\n",
                "\n",
                "num_classes = file_len('train/_darknet.labels')\n",
                "max_batches = num_classes*2000\n",
                "steps1 = .8 * max_batches\n",
                "steps2 = .9 * max_batches\n",
                "steps_str = str(steps1)+','+str(steps2)\n",
                "num_filters = (num_classes + 5) * 3\n",
                "\n",
                "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
                "\n",
                "# Instructions from the darknet repo\n",
                "# change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
                "# change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
                "# if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/content/darknet\n"
                    ]
                }
            ],
            "source": [
                "%cd /content/darknet/\n",
                "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
                "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
                "\n",
                "@register_line_cell_magic\n",
                "def writetemplate(line, cell):\n",
                "    with open(line, 'w') as f:\n",
                "        f.write(cell.format(**globals()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
                "[net]\n",
                "# Testing\n",
                "#batch=1\n",
                "#subdivisions=1\n",
                "# Training\n",
                "batch=64\n",
                "subdivisions=16\n",
                "width=416\n",
                "height=416\n",
                "channels=3\n",
                "momentum=0.9\n",
                "decay=0.0005\n",
                "angle=0\n",
                "saturation = 1.5\n",
                "exposure = 1.5\n",
                "hue=.1\n",
                "\n",
                "learning_rate=0.00261\n",
                "burn_in=1000\n",
                "max_batches = {max_batches}\n",
                "policy=steps\n",
                "steps={steps_str}\n",
                "scales=.1,.1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=2\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=2\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=32\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=64\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers=-1\n",
                "groups=2\n",
                "group_id=1\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -1,-2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[route]\n",
                "layers = -6,-1\n",
                "\n",
                "[maxpool]\n",
                "size=2\n",
                "stride=2\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=512\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "##################################\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=512\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "filters={num_filters}\n",
                "activation=linear\n",
                "\n",
                "[yolo]\n",
                "mask = 3,4,5\n",
                "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                "classes={num_classes}\n",
                "num=6\n",
                "jitter=.3\n",
                "scale_x_y = 1.05\n",
                "cls_normalizer=1.0\n",
                "iou_normalizer=0.07\n",
                "iou_loss=ciou\n",
                "ignore_thresh = .7\n",
                "truth_thresh = 1\n",
                "random=0\n",
                "nms_kind=greedynms\n",
                "beta_nms=0.6\n",
                "\n",
                "[route]\n",
                "layers = -4\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=128\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[upsample]\n",
                "stride=2\n",
                "\n",
                "[route]\n",
                "layers = -1, 23\n",
                "\n",
                "[convolutional]\n",
                "batch_normalize=1\n",
                "filters=256\n",
                "size=3\n",
                "stride=1\n",
                "pad=1\n",
                "activation=leaky\n",
                "\n",
                "[convolutional]\n",
                "size=1\n",
                "stride=1\n",
                "pad=1\n",
                "filters={num_filters}\n",
                "activation=linear\n",
                "\n",
                "[yolo]\n",
                "mask = 1,2,3\n",
                "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                "classes={num_classes}\n",
                "num=6\n",
                "jitter=.3\n",
                "scale_x_y = 1.05\n",
                "cls_normalizer=1.0\n",
                "iou_normalizer=0.07\n",
                "iou_loss=ciou\n",
                "ignore_thresh = .7\n",
                "truth_thresh = 1\n",
                "random=0\n",
                "nms_kind=greedynms\n",
                "beta_nms=0.6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[net]\n",
                        "# Testing\n",
                        "#batch=1\n",
                        "#subdivisions=1\n",
                        "# Training\n",
                        "batch=64\n",
                        "subdivisions=16\n",
                        "width=416\n",
                        "height=416\n",
                        "channels=3\n",
                        "momentum=0.9\n",
                        "decay=0.0005\n",
                        "angle=0\n",
                        "saturation = 1.5\n",
                        "exposure = 1.5\n",
                        "hue=.1\n",
                        "\n",
                        "learning_rate=0.00261\n",
                        "burn_in=1000\n",
                        "max_batches = 10000\n",
                        "policy=steps\n",
                        "steps=8000.0,9000.0\n",
                        "scales=.1,.1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=2\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=2\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=32\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=64\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers=-1\n",
                        "groups=2\n",
                        "group_id=1\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -1,-2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[route]\n",
                        "layers = -6,-1\n",
                        "\n",
                        "[maxpool]\n",
                        "size=2\n",
                        "stride=2\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=512\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "##################################\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=512\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "filters=30\n",
                        "activation=linear\n",
                        "\n",
                        "[yolo]\n",
                        "mask = 3,4,5\n",
                        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                        "classes=5\n",
                        "num=6\n",
                        "jitter=.3\n",
                        "scale_x_y = 1.05\n",
                        "cls_normalizer=1.0\n",
                        "iou_normalizer=0.07\n",
                        "iou_loss=ciou\n",
                        "ignore_thresh = .7\n",
                        "truth_thresh = 1\n",
                        "random=0\n",
                        "nms_kind=greedynms\n",
                        "beta_nms=0.6\n",
                        "\n",
                        "[route]\n",
                        "layers = -4\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=128\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[upsample]\n",
                        "stride=2\n",
                        "\n",
                        "[route]\n",
                        "layers = -1, 23\n",
                        "\n",
                        "[convolutional]\n",
                        "batch_normalize=1\n",
                        "filters=256\n",
                        "size=3\n",
                        "stride=1\n",
                        "pad=1\n",
                        "activation=leaky\n",
                        "\n",
                        "[convolutional]\n",
                        "size=1\n",
                        "stride=1\n",
                        "pad=1\n",
                        "filters=30\n",
                        "activation=linear\n",
                        "\n",
                        "[yolo]\n",
                        "mask = 1,2,3\n",
                        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
                        "classes=5\n",
                        "num=6\n",
                        "jitter=.3\n",
                        "scale_x_y = 1.05\n",
                        "cls_normalizer=1.0\n",
                        "iou_normalizer=0.07\n",
                        "iou_loss=ciou\n",
                        "ignore_thresh = .7\n",
                        "truth_thresh = 1\n",
                        "random=0\n",
                        "nms_kind=greedynms\n",
                        "beta_nms=0.6\n"
                    ]
                }
            ],
            "source": [
                "# here is the file that was just written.\n",
                "# you may consider adjusting certain things\n",
                "\n",
                "# like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
                "# if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
                "%cat cfg/custom-yolov4-tiny-detector.cfg\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Custom YOLOv4 Detector"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 - dont_show - map\n",
                "# If you get CUDA out of memory adjust subdivisions above!\n",
                "# adjust max batches down for shorter training above\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
